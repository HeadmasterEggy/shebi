import argparse

import matplotlib.pyplot as plt
import pandas as pd
from scipy.ndimage import gaussian_filter1d


# è®¾ç½®å…¨å±€å­—ä½“ä¸ºå®‹ä½“
def set_plot_style():
    """è®¾ç½®matplotlibçš„å…¨å±€æ ·å¼ï¼ŒåŒ…æ‹¬ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    plt.style.use("seaborn-v0_8-muted")

    # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œæ”¯æŒä¸åŒå¹³å°
    plt.rcParams['font.family'] = ['Songti SC']  # macOS
    plt.rcParams['axes.unicode_minus'] = False  # ç¡®ä¿è´Ÿå·æ­£ç¡®æ˜¾ç¤º
    plt.rcParams['font.size'] = 12  # è®¾ç½®é»˜è®¤å­—ä½“å¤§å°


def plot_training_log(model_name=None, save_path=None, compare=False):
    """
    ç»˜åˆ¶è®­ç»ƒæ—¥å¿—æ›²çº¿ï¼Œæ”¯æŒå•æ¨¡å‹æˆ–æ¨¡å‹æ¯”è¾ƒ

    å‚æ•°ï¼š
        model_name: æ¨¡å‹åç§° ('bi_lstm_attention', 'bi_lstm', 'lstm_attention', 'lstm', 'cnn')ï¼Œå¦‚æœä¸ºNoneä¸”compare=Falseï¼Œåˆ™ä½¿ç”¨é»˜è®¤æ—¥å¿—å
        save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        compare: æ˜¯å¦æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
    """
    if compare:
        # æ¯”è¾ƒæ¨¡å¼ï¼šåŠ è½½å¤šä¸ªæ¨¡å‹çš„æ•°æ®
        models = ['bi_lstm_attention', 'bi_lstm', 'lstm_attention', 'lstm', 'cnn']
        dfs = {}

        for model in models:
            log_path = f"train_log_{model}.csv"
            try:
                df = pd.read_csv(log_path)
                # è‡ªåŠ¨è¯†åˆ«å¹¶æŒ‰ epoch èšåˆï¼ˆå…¼å®¹ step çº§æ—¥å¿—ï¼‰
                if df["epoch"].duplicated().any():
                    print(f"ğŸ“Œ æ£€æµ‹åˆ° {model} æ¯stepæ—¥å¿—ï¼Œè‡ªåŠ¨æŒ‰epochèšåˆ...")
                    df = df.groupby("epoch", as_index=False).mean()
                dfs[model] = df
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åŠ è½½ {model} æ¨¡å‹æ—¥å¿—: {e}")
                # ä¸è¿”å›ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ¨¡å‹
                continue

        if not dfs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹æ—¥å¿—")
            return

        if not save_path:
            save_path = "training_metrics_comparison.png"

        plot_comparison(dfs, save_path)
    else:
        # å•æ¨¡å‹æ¨¡å¼
        model_suffix = f"_{model_name}" if model_name else ""
        log_path = f"train_log{model_suffix}.csv"

        if not save_path:
            model_info = f"_{model_name}" if model_name else ""
            save_path = f"training_metrics{model_info}.png"

        try:
            df = pd.read_csv(log_path)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½è®­ç»ƒæ—¥å¿— {log_path}: {e}")
            return

        # è‡ªåŠ¨è¯†åˆ«å¹¶æŒ‰ epoch èšåˆï¼ˆå…¼å®¹ step çº§æ—¥å¿—ï¼‰
        if df["epoch"].duplicated().any():
            print("ğŸ“Œ æ£€æµ‹åˆ°æ¯stepæ—¥å¿—ï¼Œè‡ªåŠ¨æŒ‰epochèšåˆ...")
            df = df.groupby("epoch", as_index=False).mean()

        plot_single_model(df, save_path, model_name)


def plot_single_model(df, save_path, model_name=None):
    """ä¸ºå•ä¸ªæ¨¡å‹ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡å›¾"""
    # è®¾ç½®å­—ä½“
    set_plot_style()

    epochs = df["epoch"]
    smooth_sigma = 1.5

    def smooth_or_raw(col):
        return gaussian_filter1d(df[col], sigma=smooth_sigma) if col in df else None

    loss_s = smooth_or_raw("train_loss")
    acc_s = smooth_or_raw("train_acc")
    f1_s = smooth_or_raw("f1")
    recall_s = smooth_or_raw("recall")

    val_loss_s = smooth_or_raw("val_loss")
    val_acc_s = smooth_or_raw("val_acc")
    val_f1_s = smooth_or_raw("val_f1")
    val_recall_s = smooth_or_raw("val_recall")

    plt.figure(figsize=(16, 10))

    model_title = f" ({model_name.upper()})" if model_name else ""

    # --- Loss ---
    plt.subplot(2, 2, 1)
    if loss_s is not None:
        plt.plot(epochs, loss_s, label="Train Loss", color="#E74C3C", linewidth=2)
        plt.scatter(epochs, df["train_loss"], color="#E74C3C", s=20, alpha=0.3)
    if val_loss_s is not None:
        plt.plot(epochs, val_loss_s, label="Val Loss", color="#8E44AD", linestyle="--", linewidth=2)
        plt.scatter(epochs, df["val_loss"], color="#8E44AD", s=20, alpha=0.3)
    plt.title(f"Loss Curve{model_title}")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()

    # --- Accuracy ---
    plt.subplot(2, 2, 2)
    if acc_s is not None:
        plt.plot(epochs, acc_s, label="Train Acc", color="#3498DB", linewidth=2)
        plt.scatter(epochs, df["train_acc"], color="#3498DB", s=20, alpha=0.3)

        # Highlight max train accuracy
        max_train_idx = df["train_acc"].idxmax()
        max_train_epoch = df.loc[max_train_idx, "epoch"]
        max_train_acc = df.loc(max_train_idx, "train_acc")
        plt.scatter(max_train_epoch, max_train_acc, color="#3498DB", s=100, edgecolor='black', zorder=5)
        plt.annotate(f"Max: {max_train_acc:.2f}%",
                     (max_train_epoch, max_train_acc),
                     textcoords="offset points",
                     xytext=(-15, 10),
                     ha='center',
                     fontweight='bold',
                     bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8))

    if val_acc_s is not None:
        plt.plot(epochs, val_acc_s, label="Val Acc", color="#34495E", linestyle="--", linewidth=2)
        plt.scatter(epochs, df["val_acc"], color="#34495E", s=20, alpha=0.3)

        # Highlight max validation accuracy
        max_val_idx = df["val_acc"].idxmax()
        max_val_epoch = df.loc[max_val_idx, "epoch"]
        max_val_acc = df.loc[max_val_idx, "val_acc"]
        plt.scatter(max_val_epoch, max_val_acc, color="#34495E", s=100, edgecolor='black', zorder=5)
        plt.annotate(f"Max: {max_val_acc:.2f}%",
                     (max_val_epoch, max_val_acc),
                     textcoords="offset points",
                     xytext=(15, -15),
                     ha='center',
                     fontweight='bold',
                     bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8))

    plt.title(f"Accuracy{model_title}")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.grid(True)
    plt.legend()

    # --- F1 ---
    plt.subplot(2, 2, 3)
    if f1_s is not None:
        plt.plot(epochs, f1_s, label="Train F1", color="#2ECC71", linewidth=2)
        plt.scatter(epochs, df["f1"], color="#2ECC71", s=20, alpha=0.3)
    if val_f1_s is not None:
        plt.plot(epochs, val_f1_s, label="Val F1", color="#1ABC9C", linestyle="--", linewidth=2)
        plt.scatter(epochs, df["val_f1"], color="#1ABC9C", s=20, alpha=0.3)
    plt.title(f"F1 Score{model_title}")
    plt.xlabel("Epoch")
    plt.ylabel("F1 (%)")
    plt.grid(True)
    plt.legend()

    # --- Recall ---
    plt.subplot(2, 2, 4)
    if recall_s is not None:
        plt.plot(epochs, recall_s, label="Train Recall", color="#F1C40F", linewidth=2)
        plt.scatter(epochs, df["recall"], color="#F1C40F", s=20, alpha=0.3)
    if val_recall_s is not None:
        plt.plot(epochs, val_recall_s, label="Val Recall", color="#D35400", linestyle="--", linewidth=2)
        plt.scatter(epochs, df["val_recall"], color="#D35400", s=20, alpha=0.3)
    plt.title(f"Recall{model_title}")
    plt.xlabel("Epoch")
    plt.ylabel("Recall (%)")
    plt.grid(True)
    plt.legend()

    plt.tight_layout(h_pad=2)
    plt.savefig(save_path, dpi=150)
    print(f"âœ… è®­ç»ƒå›¾å·²ä¿å­˜è‡³ï¼š{save_path}")
    plt.close()


def plot_comparison(dfs, save_path):
    """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„è®­ç»ƒæŒ‡æ ‡"""
    # è®¾ç½®å­—ä½“
    set_plot_style()

    plt.figure(figsize=(16, 10))

    # å®šä¹‰æ¯ä¸ªæ¨¡å‹çš„é¢œè‰²
    colors = {
        'bi_lstm_attention': {'train': '#3498DB', 'val': '#2874A6'},  # è“è‰²ç³»
        'bi_lstm': {'train': '#9B59B6', 'val': '#8E44AD'},  # ç´«è‰²ç³»
        'lstm_attention': {'train': '#2ECC71', 'val': '#27AE60'},  # ç»¿è‰²ç³»
        'lstm': {'train': '#F1C40F', 'val': '#D35400'},  # é»„è‰²ç³»
        'cnn': {'train': '#E74C3C', 'val': '#922B21'}  # çº¢è‰²ç³»
    }

    # æŒ‡æ ‡åç§°å’Œå®ƒä»¬çš„ä½ç½®
    metrics = {
        'Loss': {'pos': 1, 'col': 'train_loss', 'val_col': 'val_loss', 'ylabel': 'Loss', 'magnify': False},
        'Accuracy': {'pos': 2, 'col': 'train_acc', 'val_col': 'val_acc', 'ylabel': 'Accuracy (%)', 'magnify': True},
        'F1': {'pos': 3, 'col': 'f1', 'val_col': 'val_f1', 'ylabel': 'F1 (%)', 'magnify': True},
        'Recall': {'pos': 4, 'col': 'recall', 'val_col': 'val_recall', 'ylabel': 'Recall (%)', 'magnify': True}
    }

    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºå­å›¾
    for metric_name, metric_info in metrics.items():
        plt.subplot(2, 2, metric_info['pos'])

        # ç”¨äºæ”¶é›†æ•°æ®èŒƒå›´çš„åˆ—è¡¨
        all_values = []

        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹çš„æŒ‡æ ‡
        for model_name, df in dfs.items():
            epochs = df["epoch"]
            train_col = metric_info['col']
            val_col = metric_info['val_col']

            # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¹¶ç¡®ä¿æ¨¡å‹é¢œè‰²é…ç½®å­˜åœ¨
            if train_col in df.columns and model_name in colors:
                # å¹³æ»‘å¤„ç†
                train_data = gaussian_filter1d(df[train_col], sigma=1.5)
                plt.plot(epochs, train_data,
                         label=f"{model_name.upper()} Train",
                         color=colors[model_name]['train'],
                         linewidth=2)
                plt.scatter(epochs, df[train_col],
                            color=colors[model_name]['train'], s=20, alpha=0.3)

                # æ”¶é›†æ•°æ®èŒƒå›´
                all_values.extend(df[train_col].tolist())

                # For accuracy metric, highlight the maximum point
                if metric_name == 'Accuracy':
                    max_idx = df[train_col].idxmax()
                    max_epoch = df.loc[max_idx, "epoch"]
                    max_val = df.loc[max_idx, train_col]
                    plt.scatter(max_epoch, max_val, color=colors[model_name]['train'], s=100, edgecolor='black',
                                zorder=5)
                    plt.annotate(f"{model_name.upper()}: {max_val:.2f}%",
                                 (max_epoch, max_val),
                                 textcoords="offset points",
                                 xytext=(0, 10),
                                 ha='center',
                                 fontweight='bold',
                                 bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8))

            # æ£€æŸ¥éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if val_col in df.columns and model_name in colors:
                val_data = gaussian_filter1d(df[val_col], sigma=1.5)
                plt.plot(epochs, val_data,
                         label=f"{model_name.upper()} Val",
                         color=colors[model_name]['val'],
                         linewidth=2, linestyle='--')
                plt.scatter(epochs, df[val_col],
                            color=colors[model_name]['val'], s=20, alpha=0.3)

                # æ”¶é›†æ•°æ®èŒƒå›´
                all_values.extend(df[val_col].tolist())

                # For accuracy metric, highlight the maximum point
                if metric_name == 'Accuracy':
                    max_val_idx = df[val_col].idxmax()
                    max_val_epoch = df.loc[max_val_idx, "epoch"]
                    max_val_acc = df.loc[max_val_idx, val_col]
                    plt.scatter(max_val_epoch, max_val_acc, color=colors[model_name]['val'], s=100, edgecolor='black',
                                zorder=5)
                    plt.annotate(f"{model_name.upper()} Val: {max_val_acc:.2f}%",
                                 (max_val_epoch, max_val_acc),
                                 textcoords="offset points",
                                 xytext=(0, -15),
                                 ha='center',
                                 fontweight='bold',
                                 bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8))

        # è°ƒæ•´Yè½´èŒƒå›´ä»¥æ”¾å¤§å·®å¼‚ (ä»…å¯¹æŒ‡å®šçš„æŒ‡æ ‡)
        if metric_info['magnify'] and all_values:
            # å¦‚æœæ˜¯ç™¾åˆ†æ¯”æŒ‡æ ‡ (Accuracy, F1, Recall)
            if "%" in metric_info['ylabel']:
                # æ‰¾å‡ºæ•°æ®çš„æœ€å°å’Œæœ€å¤§å€¼
                min_val = max(min(all_values) - 2, 0)  # ä¸‹é™ä¸ä½äº0
                max_val = min(max(all_values) + 2, 100)  # ä¸Šé™ä¸è¶…è¿‡100

                # ä½¿ç”¨å››åˆ†ä½èŒƒå›´æ”¾å¤§å·®å¼‚ (å»æ‰ç¦»ç¾¤å€¼)
                values = sorted(all_values)
                q1 = values[int(len(values) * 0.25)]
                q3 = values[int(len(values) * 0.75)]

                # æ ¹æ®æ•°æ®åˆ†å¸ƒè®¾ç½®é€‚å½“çš„æ”¾å¤§èŒƒå›´ï¼Œè‡³å°‘ä¿ç•™5ä¸ªç™¾åˆ†ç‚¹çš„é—´éš”
                y_min = max(min_val, q1 - (q3 - q1) * 0.5)
                y_max = min(max_val, q3 + (q3 - q1) * 0.5)

                # ç¡®ä¿èŒƒå›´è‡³å°‘æœ‰5ä¸ªç™¾åˆ†ç‚¹ï¼Œå¦åˆ™æ‰‹åŠ¨æ‰©å¤§
                if y_max - y_min < 5:
                    mid = (y_min + y_max) / 2
                    y_min = max(0, mid - 2.5)
                    y_max = min(100, mid + 2.5)

                plt.ylim(y_min, y_max)

                # æ·»åŠ æ³¨é‡Šè¯´æ˜Yè½´èŒƒå›´å·²è¢«ç¼©æ”¾
                plt.annotate(f"* Yè½´å·²ç¼©æ”¾è‡³ [{y_min:.1f}%, {y_max:.1f}%] ä»¥çªæ˜¾å·®å¼‚",
                             xy=(0.5, 0.01),
                             xycoords='axes fraction',
                             ha='center',
                             va='bottom',
                             fontsize=8,
                             style='italic',
                             color='gray')
            else:
                # å¯¹äºLossï¼Œå¯èƒ½ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œæˆ–è€…ä½¿ç”¨ä¸åŒçš„é€»è¾‘
                pass

        plt.title(f"{metric_name} Comparison")
        plt.xlabel("Epoch")
        plt.ylabel(metric_info['ylabel'])
        plt.grid(True)
        plt.legend()

    plt.tight_layout(h_pad=2)
    plt.savefig(save_path, dpi=150)
    print(f"âœ… æ¨¡å‹æ¯”è¾ƒå›¾å·²ä¿å­˜è‡³ï¼š{save_path}")
    plt.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ç»˜åˆ¶è®­ç»ƒæ—¥å¿—')
    parser.add_argument('--model', type=str,
                        choices=['bi_lstm_attention', 'bi_lstm', 'lstm_attention', 'lstm', 'cnn'],
                        help='æŒ‡å®šæ¨¡å‹ç±»å‹')
    parser.add_argument('--output', type=str, help='è¾“å‡ºå›¾åƒè·¯å¾„')
    parser.add_argument('--compare', action='store_true', help='æ¯”è¾ƒå¤šä¸ªæ¨¡å‹')
    args = parser.parse_args()

    plot_training_log(model_name=args.model, save_path=args.output, compare=args.compare)
